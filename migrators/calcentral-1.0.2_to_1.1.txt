MIGRATING 1.0.2 TO 1.1.0

1. Make sure this MySQL configuration variable is at least this large in my.cnf:

[mysql]
max_allowed_packet=20M

Otherwise 1.1 startup will fail in a big way.

Also ensure that the "myberkeley" account has a "maximum open files" limit of 2048
(rather than the default 1024). This should head off the Solr indexing bug described
at MYB-1251 and MYB-1302.

2. While v1.0.2 is still running, delete /var to give the new search templates room to drop in

curl -u admin:'ADMIN_PASSWORD' -e http://localhost:8080 http://localhost:8080/var -F":operation=delete"
curl -u admin:'ADMIN_PASSWORD' -e http://localhost:8080 http://localhost:8080/var -F "jcr:primaryType"="sling:Folder"

Now stop v1.0.2 and update the code from Git.

mvn -e -P runner -Dsling.stop verify
cd ../3akai-ux/
git fetch -p origin
git checkout dev
git pull
git checkout calcentral-1.1
cd ../myberkeley/
git fetch -p origin
git checkout .
git checkout dev
git pull
git checkout calcentral-1.1

3. Blow away some old sling directories:

mvn -e -Dsling.purge -P runner clean
rm -rf working/sling/solr

(Our Maven procedures take care of the OAE Confluence page's steps 3, 5, and 6.)

4. Run the database migration script:

mysql -p -u sakaiuser nakamura < migrators/src/main/scripts/calcentral-mysql-1.0.2_to_1.1.sql

5. Update configurations. On the calcentral servers, this means adding two new lines to
"~/.build.cf":

MYSQL_PASSWORD=xxx
ORACLE_URL=yyy

6. Start v1.1 over the existing Sling directory. On the calcentral servers, we do this
via the usual "reinstall.sh" run. DON'T ALLOW USERS ON YET!

7. Force a complete Solr re-indexing so that the database migration code can search successfully:

curl -i -L -g -u admin:'ADMIN_PASSWORD' -e http://localhost:8080 -X POST \
  'http://localhost:8080/system/console/solr?type=all'

(Yes, you must use a GET-style query string in a POST request.)

Watch the server log for progress. On my laptop this took 35 minutes to finish. On
calcentral-staging it took about 12 minutes.

8. Run /system/sparseupgrade to migrate data, move to the new Sparse indexing schema, and
re-re-index Solr:

curl -N -u admin:'ADMIN_PASSWORD' -e http://localhost:8080 -FdryRun=false \
  -FreindexAll=true http://localhost:8080/system/sparseupgrade

You may see many "Counter cachedStatement Leaking" messages due to a Sparse bug:
https://jira.sakaiproject.org/browse/KERN-2445

The Sparse job took about 20 minutes on my laptop and about 10 minutes on
calcentral-staging. The Solr re-indexing takes the same amount of time as in
step 7.

9. Before re-enabling preview generation on mboo, make sure that "nakamura" has been
updated to the correct Git tag or branch and that "/etc/init.d/monitorserver" and
"/home/myberkeley/.build.cf" has an entry for "APPLICATION_TERM_EXTRACT_SVR".
